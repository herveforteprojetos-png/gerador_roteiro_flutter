import 'dart:math';
import 'package:dio/dio.dart';
import 'package:flutter/foundation.dart';

/// ğŸ¤– LlmClient - Cliente para comunicaÃ§Ã£o com APIs de LLM (Gemini)
///
/// ResponsÃ¡vel por:
/// - InicializaÃ§Ã£o e configuraÃ§Ã£o do cliente HTTP
/// - GestÃ£o de API Keys
/// - Chamadas Ã  API Gemini
/// - MÃ©todos simplificados: `generateText` e `generateJson`
///
/// Parte da refatoraÃ§Ã£o SOLID do GeminiService v7.6.64
class LlmClient {
  final Dio _dio;
  final String _instanceId;

  /// ğŸ“ Helper padronizado para logs (mantÃ©m emojis em debug, limpa em produÃ§Ã£o)
  static void _log(String message, {String level = 'info'}) {
    if (kDebugMode) {
      debugPrint(message);
    } else if (level == 'error' || level == 'critical') {
      final cleaned = message
          .replaceAll(RegExp(r'[ğŸš¨ğŸ”¥âœ…âŒâš ï¸ğŸ’¡ğŸ“ŠğŸ¯ğŸ“ğŸ”—ğŸ“šğŸ¤–ğŸŒ]'), '')
          .trim();
      debugPrint('[${level.toUpperCase()}] $cleaned');
    }
  }

  /// Modelos disponÃ­veis no Gemini
  static const String modelFlash = 'gemini-2.5-flash';
  static const String modelPro = 'gemini-2.5-pro';
  static const String modelUltra = 'gemini-3-pro-preview';

  /// Construtor com injeÃ§Ã£o de dependÃªncias opcional
  LlmClient({Dio? dio, String? instanceId})
    : _dio = dio ?? _createDefaultDio(),
      _instanceId = instanceId ?? _genInstanceId();

  /// Cria instÃ¢ncia padrÃ£o do Dio com configuraÃ§Ãµes otimizadas
  static Dio _createDefaultDio() {
    return Dio(
      BaseOptions(
        connectTimeout: const Duration(seconds: 45),
        receiveTimeout: const Duration(minutes: 5),
        sendTimeout: const Duration(seconds: 45),
      ),
    );
  }

  /// Gera ID Ãºnico para a instÃ¢ncia
  static String _genInstanceId() {
    final random = Random();
    return 'llm_${random.nextInt(9999).toString().padLeft(4, '0')}';
  }

  /// ğŸ¯ Helper para selecionar modelo baseado no qualityMode
  ///
  /// - 'flash': RÃ¡pido e eficiente (gemini-2.5-flash)
  /// - 'pro': MÃ¡xima qualidade (gemini-2.5-pro) - PADRÃƒO
  /// - 'ultra': Modelo mais avanÃ§ado (gemini-3-pro-preview)
  static String getModelForQuality(String qualityMode) {
    switch (qualityMode.toLowerCase()) {
      case 'flash':
        return modelFlash;
      case 'ultra':
        return modelUltra;
      case 'pro':
      default:
        return modelPro;
    }
  }

  /// ğŸ”§ Gera texto usando a API Gemini
  ///
  /// [prompt]: O prompt a ser enviado
  /// [apiKey]: Chave da API Gemini
  /// [model]: Modelo a ser usado (use [getModelForQuality] para obter)
  /// [maxTokens]: MÃ¡ximo de tokens na resposta
  /// [temperature]: Temperatura (criatividade) - padrÃ£o ajustado por modelo
  ///
  /// Retorna: Texto gerado ou string vazia em caso de erro
  Future<String> generateText({
    required String prompt,
    required String apiKey,
    required String model,
    int maxTokens = 8192,
    double? temperature,
  }) async {
    try {
      // Ajustar temperatura baseado no modelo se nÃ£o especificado
      final effectiveTemperature = temperature ?? _getDefaultTemperature(model);

      final response = await _makeRequest(
        apiKey: apiKey,
        model: model,
        prompt: prompt,
        maxTokens: maxTokens,
        temperature: effectiveTemperature,
      );

      return response ?? '';
    } catch (e) {
      _log('âŒ Erro em generateText: $e', level: 'error');
      rethrow;
    }
  }

  /// ğŸ¯ ObtÃ©m temperatura padrÃ£o otimizada por modelo
  double _getDefaultTemperature(String model) {
    if (model == modelFlash) {
      // Flash: temperatura balanceada (0.6 causava muitas repetiÃ§Ãµes)
      return 0.7;
    } else if (model == modelPro) {
      // Pro: temperatura alta para mÃ¡xima criatividade
      return 0.8;
    } else {
      // Ultra: temperatura balanceada
      return 0.7;
    }
  }

  /// ğŸ”§ Gera JSON estruturado usando a API Gemini
  ///
  /// Ãštil para extraÃ§Ã£o de dados estruturados (ex: World State)
  ///
  /// [prompt]: O prompt a ser enviado (deve instruir formato JSON)
  /// [apiKey]: Chave da API Gemini
  /// [model]: Modelo a ser usado
  /// [maxTokens]: MÃ¡ximo de tokens na resposta
  ///
  /// Retorna: Texto JSON ou string vazia em caso de erro
  Future<String> generateJson({
    required String prompt,
    required String apiKey,
    required String model,
    int maxTokens = 2048,
  }) async {
    try {
      // Temperatura mais baixa para JSON consistente
      final response = await _makeRequest(
        apiKey: apiKey,
        model: model,
        prompt: prompt,
        maxTokens: maxTokens,
        temperature: 0.3, // Baixa temperatura para JSON estruturado
      );

      return response ?? '';
    } catch (e) {
      _log('âŒ Erro em generateJson: $e', level: 'error');
      rethrow;
    }
  }

  /// ğŸ”§ Faz requisiÃ§Ã£o Ã  API Gemini
  ///
  /// MÃ©todo interno que realiza a chamada HTTP
  Future<String?> _makeRequest({
    required String apiKey,
    required String model,
    required String prompt,
    required int maxTokens,
    double temperature = 0.8,
  }) async {
    try {
      // Ajustar maxTokens para limites da API
      final adjustedMaxTokens = maxTokens < 8192
          ? 8192
          : min(maxTokens * 2, 32768);

      final resp = await _dio.post(
        'https://generativelanguage.googleapis.com/v1beta/models/$model:generateContent',
        queryParameters: {'key': apiKey},
        data: {
          'contents': [
            {
              'parts': [
                {'text': prompt},
              ],
            },
          ],
          'generationConfig': {
            'temperature': temperature,
            'topK': 40,
            'topP': 0.95,
            'maxOutputTokens': adjustedMaxTokens,
          },
        },
      );

      if (kDebugMode) {
        debugPrint('[$_instanceId] Status Code: ${resp.statusCode}');
      }

      // Verificar erro na resposta
      if (resp.data['error'] != null) {
        debugPrint('[$_instanceId] API Error: ${resp.data['error']}');
        throw Exception('API Error: ${resp.data['error']['message']}');
      }

      // Verificar bloqueio de conteÃºdo
      final promptFeedback = resp.data['promptFeedback'];
      if (promptFeedback != null && promptFeedback['blockReason'] != null) {
        final blockReason = promptFeedback['blockReason'];
        _log('ğŸš« CONTEÃšDO BLOQUEADO - RazÃ£o: $blockReason', level: 'error');
        return null;
      }

      // Verificar finish reason
      final finishReason = resp.data['candidates']?[0]?['finishReason'];
      if (finishReason == 'MAX_TOKENS' && kDebugMode) {
        debugPrint(
          '[$_instanceId] Aviso - Resposta cortada por limite de tokens',
        );
      }

      // Extrair texto da resposta
      String? result;
      final candidate = resp.data['candidates']?[0];

      if (candidate != null) {
        result = candidate['content']?['parts']?[0]?['text'] as String?;

        if (result == null || result.isEmpty) {
          result = candidate['content']?['text'] as String?;
        }

        if (result == null || result.isEmpty) {
          result = candidate['text'] as String?;
        }
      }

      if (kDebugMode) {
        debugPrint(
          '[$_instanceId] Extracted text: ${result?.length ?? 0} chars',
        );
      }

      // Limpar texto de marcaÃ§Ãµes indesejadas
      if (result != null) {
        result = _cleanGeneratedText(result);
      }

      return result;
    } catch (e) {
      _log('âŒ Erro na requisiÃ§Ã£o API: $e', level: 'error');
      
      // ğŸš¨ Tratamento especial para erro 429 (Rate Limit)
      if (e.toString().contains('429')) {
        _log('âš ï¸ Rate Limit atingido - aguarde antes de nova tentativa', level: 'warning');
      }
      
      rethrow;
    }
  }

  /// Limpa texto de marcaÃ§Ãµes indesejadas
  String _cleanGeneratedText(String text) {
    return text
        .replaceAll(RegExp(r'CONTINUAÃ‡ÃƒO:\s*', caseSensitive: false), '')
        .replaceAll(RegExp(r'CONTEXTO FINAL:\s*', caseSensitive: false), '')
        .replaceAll(RegExp(r'\n\n\n+'), '\n\n')
        .trim();
  }

  /// ğŸ”§ Verifica se a API key Ã© vÃ¡lida fazendo uma requisiÃ§Ã£o simples
  Future<bool> validateApiKey(String apiKey) async {
    try {
      final response = await _dio.post(
        'https://generativelanguage.googleapis.com/v1beta/models/$modelFlash:generateContent',
        queryParameters: {'key': apiKey},
        data: {
          'contents': [
            {
              'parts': [
                {'text': 'Hello'},
              ],
            },
          ],
          'generationConfig': {'maxOutputTokens': 10},
        },
      );

      return response.statusCode == 200;
    } catch (e) {
      return false;
    }
  }

  /// Libera recursos
  void dispose() {
    _dio.close();
  }
}
